{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import cv2\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zhoubolei/CAM/blob/master/pytorch_CAM.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a class $c$\n",
    "\n",
    "$$\\text{cam at $(x,y)$} = M_c(x,y) = \\sum_k w_k f_k(x,y)$$\n",
    "\n",
    "$$\\text{resulf of GAP for unit $k$} = F_k = \\sum_{x,y} f_k(x,y)$$\n",
    "\n",
    "\\begin{align}\n",
    "S_c & = \\sum_k w_k F_k\\\\\n",
    "& = \\sum_k w_k \\sum_{x,y} f_k(x,y)\\\\\n",
    "& = \\sum_k \\sum_{x,y} w_k f_k(x,y)\\\\\n",
    "& = \\sum_{x,y} \\sum_k w_k f_k(x,y)\\\\\n",
    "& = \\sum_{x,y} M_c(x,y)\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnet18(pretrained=True)\n",
    "finalconv_name = 'layer4'\n",
    "\n",
    "net.eval()\n",
    "\n",
    "# hook the feature extractor\n",
    "features_blobs = []\n",
    "def hook_feature(module, input, output):\n",
    "    features_blobs.append(output.data.cpu().numpy())\n",
    "\n",
    "net._modules.get(finalconv_name).register_forward_hook(hook_feature)\n",
    "\n",
    "# get the softmax weight\n",
    "params = list(net.parameters())\n",
    "weight_softmax = np.squeeze(params[-2].data.numpy())\n",
    "\n",
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    # batch?, \n",
    "    # nc = n in paper with unit k = 0, ..., n-1 \n",
    "    # h = height with x = 0, ..., h-1 \n",
    "    # w = width with y = 0, ..., w-1\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    output_cam = []\n",
    "    for idx in class_idx:\n",
    "        # cam.shape = (1, 512) @_shape (512, 49) = (1, 49)\n",
    "        cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "        cam = cam.reshape(h, w) # (7, 7)\n",
    "        # Min-max normalization\n",
    "        cam = cam - np.min(cam)\n",
    "        cam_img = cam / np.max(cam)\n",
    "        cam_img = np.uint8(255 * cam_img)\n",
    "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
    "        # Output min and max\n",
    "    return output_cam\n",
    "\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((224,224)),\n",
    "   transforms.ToTensor(),\n",
    "   normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 -> container ship\n",
      "0.000 -> dock\n",
      "0.000 -> fireboat\n",
      "0.000 -> drilling rig\n",
      "0.000 -> ocean liner\n",
      "(512,)\n",
      "(512, 49)\n",
      "(49,)\n",
      "output CAM.jpg for the top1 prediction: container ship\n",
      "\n",
      "0.372 -> pirate ship\n",
      "0.367 -> paddle wheel\n",
      "0.051 -> lifeboat\n",
      "0.036 -> drilling rig\n",
      "0.030 -> dock\n",
      "(512,)\n",
      "(512, 49)\n",
      "(49,)\n",
      "output CAM.jpg for the top1 prediction: pirate ship\n",
      "\n",
      "0.164 -> station wagon\n",
      "0.108 -> tow truck\n",
      "0.106 -> race car\n",
      "0.096 -> minibus\n",
      "0.091 -> minivan\n",
      "(512,)\n",
      "(512, 49)\n",
      "(49,)\n",
      "output CAM.jpg for the top1 prediction: station wagon\n",
      "\n",
      "0.673 -> semi-trailer truck\n",
      "0.218 -> garbage truck\n",
      "0.066 -> moving van\n",
      "0.008 -> tow truck\n",
      "0.005 -> minibus\n",
      "(512,)\n",
      "(512, 49)\n",
      "(49,)\n",
      "output CAM.jpg for the top1 prediction: semi-trailer truck\n",
      "\n",
      "0.233 -> tiger cat\n",
      "0.188 -> ring-tailed lemur\n",
      "0.159 -> lynx\n",
      "0.112 -> tabby cat\n",
      "0.092 -> koala\n",
      "(512,)\n",
      "(512, 49)\n",
      "(49,)\n",
      "output CAM.jpg for the top1 prediction: tiger cat\n",
      "\n",
      "0.386 -> tricycle\n",
      "0.264 -> unicycle\n",
      "0.200 -> mountain bike\n",
      "0.126 -> tandem bicycle\n",
      "0.007 -> moped\n",
      "(512,)\n",
      "(512, 49)\n",
      "(49,)\n",
      "output CAM.jpg for the top1 prediction: tricycle\n",
      "\n",
      "0.260 -> llama\n",
      "0.137 -> German Shepherd Dog\n",
      "0.066 -> Afghan Hound\n",
      "0.054 -> collie\n",
      "0.054 -> Alaskan Malamute\n",
      "(512,)\n",
      "(512, 49)\n",
      "(49,)\n",
      "output CAM.jpg for the top1 prediction: llama\n",
      "\n",
      "0.163 -> tabby cat\n",
      "0.162 -> lynx\n",
      "0.158 -> tiger cat\n",
      "0.086 -> Persian cat\n",
      "0.056 -> cougar\n",
      "(512,)\n",
      "(512, 49)\n",
      "(49,)\n",
      "output CAM.jpg for the top1 prediction: tabby cat\n",
      "\n",
      "0.242 -> moped\n",
      "0.228 -> tricycle\n",
      "0.060 -> tandem bicycle\n",
      "0.056 -> lawn mower\n",
      "0.026 -> crutch\n",
      "(512,)\n",
      "(512, 49)\n",
      "(49,)\n",
      "output CAM.jpg for the top1 prediction: moped\n",
      "\n",
      "0.187 -> gazelle\n",
      "0.125 -> ox\n",
      "0.119 -> impala\n",
      "0.083 -> bullock cart\n",
      "0.076 -> llama\n",
      "(512,)\n",
      "(512, 49)\n",
      "(49,)\n",
      "output CAM.jpg for the top1 prediction: gazelle\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# load the imagenet category list\n",
    "with open('imagenet-simple-labels.json') as f:\n",
    "    classes = json.load(f)\n",
    "    \n",
    "images_classe = {}\n",
    "\n",
    "for image_file in os.listdir(r'C:\\Users\\Nicol\\Documents\\EPFL\\BA7\\Project\\Files\\cam\\images'):\n",
    "    if image_file.endswith(\".jpg\"):\n",
    "        \n",
    "        # load test image\n",
    "        img_pil = Image.open('images/' + image_file)\n",
    "        img_tensor = preprocess(img_pil)\n",
    "        img_variable = Variable(img_tensor.unsqueeze(0))\n",
    "        logit = net(img_variable)\n",
    "\n",
    "        h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "        probs, idx = h_x.sort(0, True)\n",
    "        probs = probs.numpy()\n",
    "        idx = idx.numpy()\n",
    "\n",
    "        # output the prediction\n",
    "        for i in range(0, 5):\n",
    "            print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))\n",
    "\n",
    "        # generate class activation mapping for the top1 prediction\n",
    "        CAMs = returnCAM(features_blobs[0], weight_softmax, [idx[0]])\n",
    "\n",
    "        # render the CAM and output\n",
    "        print('output CAM.jpg for the top1 prediction: %s'%classes[idx[0]])\n",
    "        print('')\n",
    "        images_classe[image_file] = classes[idx[0]]\n",
    "        \n",
    "        img = cv2.imread('images/' + image_file)\n",
    "        height, width, _ = img.shape\n",
    "        heatmap = cv2.applyColorMap(cv2.resize(CAMs[0],(width, height)), cv2.COLORMAP_JET)\n",
    "        result = heatmap * 0.3 + img * 0.5\n",
    "        cv2.imwrite(f'camResults/{image_file[:-4]}_CAM.jpg', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_classe_file = open(\"camResults/images_classe.json\", \"w\")\n",
    "json.dump(images_classe, images_classe_file)\n",
    "images_classe_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
