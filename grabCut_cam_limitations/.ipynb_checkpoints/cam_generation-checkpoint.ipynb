{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/zhoubolei/CAM/blob/master/pytorch_CAM.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a class $c$\n",
    "\n",
    "$$\\text{cam at $(x,y)$} = M_c(x,y) = \\sum_k w_k^c f_k(x,y)$$\n",
    "\n",
    "$$\\text{resulf of GAP for unit $k \\in \\{0, \\ldots, n-1\\}$} = F_k = \\sum_{x,y} f_k(x,y)$$\n",
    "\n",
    "$$\\text{for resnet18 $n=512$}$$\n",
    "\n",
    "\\begin{align}\n",
    "S_c & = \\sum_k w_k^c F_k\\\\\n",
    "& = \\sum_k w_k^c \\sum_{x,y} f_k(x,y)\\\\\n",
    "& = \\sum_k \\sum_{x,y} w_k^c f_k(x,y)\\\\\n",
    "& = \\sum_{x,y} \\sum_k w_k^c f_k(x,y)\\\\\n",
    "& = \\sum_{x,y} M_c(x,y)\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "S & = W_{1000 \\times 512} F_{512 \\times 1}\\\\\n",
    "& = W_{1000 \\times 512} \\sum_{x,y = 1}^7 f_{512 \\times 1}(x,y)\\\\\n",
    "& = \\sum_{x,y=1}^7 W_{1000 \\times 512} f_{512 \\times 1}(x,y)\\\\\n",
    "& = \\sum_{x,y=1}^7 M_{1000 \\times 1}(x,y)\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 512)\n"
     ]
    }
   ],
   "source": [
    "model_id = 1\n",
    "if model_id == 1:\n",
    "    net = models.squeezenet1_1(pretrained=True)\n",
    "    finalconv_name = 'features' # this is the last conv layer of the network\n",
    "elif model_id == 2:\n",
    "    net = models.resnet18(pretrained=True)\n",
    "    finalconv_name = 'layer4'\n",
    "elif model_id == 3:\n",
    "    net = models.densenet161(pretrained=True)\n",
    "    finalconv_name = 'features'\n",
    "    \n",
    "net.eval()\n",
    "\n",
    "# get the softmax weight\n",
    "params = list(net.parameters())\n",
    "weight_softmax = np.squeeze(params[-2].data.numpy())\n",
    "print(weight_softmax.shape)\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((224,224)),\n",
    "   transforms.ToTensor(),\n",
    "   normalize\n",
    "])\n",
    "\n",
    "# load the imagenet category list\n",
    "with open('imagenet-simple-labels.json') as f:\n",
    "    classes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnCAMs(feature_conv, weight_softmax):\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    cams = np.tensordot(weight_softmax, feature_conv.reshape((nc, h, w)), axes=([1],[0]))\n",
    "    return cams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnCAM(feature_conv, weight_softmax, class_idx):\n",
    "    # generate the class activation maps upsample to 256x256\n",
    "    size_upsample = (256, 256)\n",
    "    # batch?,\n",
    "    # nc = number of unit k = 0, ..., n-1 \n",
    "    # h = height with x = 0, ..., h-1 \n",
    "    # w = width with y = 0, ..., w-1\n",
    "    bz, nc, h, w = feature_conv.shape\n",
    "    # print(feature_conv.shape) = (1, 512, 7, 7)\n",
    "    # print(weight_softmax.shape) = (1000, 512)    \n",
    "    cam = weight_softmax[class_idx].dot(feature_conv.reshape((nc, h*w)))\n",
    "    # print(cam.shape) = (1, 512) @_shape (512, 49) = (1, 49)\n",
    "    return cam.reshape(h, w) # (7, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnPredictionsAndCAMs(images_pil, images_name, top = 5):\n",
    "    images_predictions = {}\n",
    "    images_CAMs = {}\n",
    "    \n",
    "    for name in images_name:\n",
    "        # hook the feature extractor\n",
    "        features_blobs = []\n",
    "        def hook_feature(module, input, output):\n",
    "            features_blobs.append(output.data.cpu().numpy())\n",
    "        net._modules.get(finalconv_name).register_forward_hook(hook_feature)\n",
    "        \n",
    "        img_tensor = preprocess(images_pil[name])\n",
    "        img_variable = Variable(img_tensor.unsqueeze(0))\n",
    "        logit = net(img_variable)\n",
    "\n",
    "        h_x = F.softmax(logit, dim=1).data.squeeze()\n",
    "        probs, idx = h_x.sort(0, True)\n",
    "        probs = probs.numpy()\n",
    "        idx = idx.numpy()\n",
    "        \n",
    "        predictions = []\n",
    "        predictionsCAMs = []\n",
    "        \n",
    "        for i in range(top):\n",
    "            predicted_class = classes[idx[i]]\n",
    "            probability = f'{probs[i]:.4f}'\n",
    "            \n",
    "            predictions.append((probability, predicted_class))\n",
    "            \n",
    "            predictionsCAMs.append(returnCAM(features_blobs[0], weight_softmax, idx[i]))\n",
    "\n",
    "        images_predictions[name] = predictions\n",
    "        images_CAMs[name] = predictionsCAMs\n",
    "            \n",
    "    return images_predictions, images_CAMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names = ['dog_moped.jpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: '\\\\images\\\\processed\\\\session_5\\\\cropped\\\\\\\\'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-97e6055f931d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m images_name, images_cv2, images_pil, _ = utils.load(input_directory, \n\u001b[0;32m      8\u001b[0m                                                     \u001b[1;31m#images_name = names,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                                                     with_bboxes = False)\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\EPFL\\BA7\\Project\\Code\\grabcut_cam_limitations\\utils.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(input_directory, images_name, with_bboxes)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mimages_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mimages_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m                 \u001b[0mimages_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: '\\\\images\\\\processed\\\\session_5\\\\cropped\\\\\\\\'"
     ]
    }
   ],
   "source": [
    "input_directory = r'images\\processed\\session_5\\cropped\\\\'\n",
    "target_directory = r'output\\session_5\\cam\\squeezenet_cropped\\\\'\n",
    "Path(target_directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAVING_MODE = True\n",
    "\n",
    "images_name, images_cv2, images_pil, _ = utils.load(input_directory, \n",
    "                                                    #images_name = names,\n",
    "                                                    with_bboxes = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_predictions, images_CAMs = returnPredictionsAndCAMs(images_pil, images_name, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renderCAM(image, CAM, size_upsample = (256, 256)):\n",
    "    CAM = CAM - np.min(CAM)\n",
    "    CAM = CAM / np.max(CAM)\n",
    "    CAM = np.uint8(255 * CAM)\n",
    "    CAM = cv2.resize(CAM, size_upsample)\n",
    "    #print(f'CAM max = {np.max(CAM)}, CAM min = {np.min(CAM)} ')\n",
    "    height, width, _ = image.shape\n",
    "    heatmap = cv2.applyColorMap(cv2.resize(CAM, (width, height)), cv2.COLORMAP_JET)\n",
    "    return heatmap * 0.3 + image * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in images_name:\n",
    "    image = images_cv2[name]\n",
    "    \n",
    "    utils.pltShow(image)\n",
    "    \n",
    "    for i in range(len(images_CAMs[name])):\n",
    "        probability = images_predictions[name][i][0]\n",
    "        predicted_class = images_predictions[name][i][1]\n",
    "        \n",
    "        print(probability, predicted_class)\n",
    "        \n",
    "        CAM = images_CAMs[name][i]\n",
    "        \n",
    "        renderedCAM = renderCAM(image, CAM)\n",
    "                             \n",
    "        utils.pltShow(renderedCAM)\n",
    "        \n",
    "        if SAVING_MODE:\n",
    "            cv2.imwrite(target_directory + \n",
    "                        f'{name[:-4]}_pred_{i+1}_proba_{probability}_class_{predicted_class}_CAM.jpg', \n",
    "                        renderedCAM)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVING_MODE:\n",
    "    images_predictions_file = open(target_directory + \"images_predictions.json\", \"w\")\n",
    "    json.dump(images_predictions, images_predictions_file, indent=4)\n",
    "    images_predictions_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
