{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils.image as im\n",
    "import utils.cam as cam\n",
    "import utils.grabcut as gc\n",
    "import utils.metrics as m\n",
    "import utils.json as json\n",
    "import utils.path as path\n",
    "from utils.VOCSegmentation import VOCSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = path.goback_from_current_dir(1)\n",
    "\n",
    "json_path = root_path + 'json\\\\'\n",
    "\n",
    "sgm_path  = root_path + 'VOCdevkit\\VOC2012\\SegmentationObject\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tbl = VOCSegmentation(root = root_path,\n",
    "                           year = '2012',\n",
    "                           image_set = 'trainval',\n",
    "                           download = False,\n",
    "                           transform = transforms.ToTensor(),\n",
    "                           target_transform = transforms.ToTensor(),\n",
    "                           transforms = None,\n",
    "                           target = 'Object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(torch.utils.data.DataLoader(data_tbl,\n",
    "                                        batch_size = 1,\n",
    "                                        shuffle = False,\n",
    "                                        num_workers = 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = json.open_json(json_path + 'voc-object-annotations')\n",
    "annotations_clean = json.open_json(json_path + 'voc-object-annotations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(annotations)\n",
    "N_TOTAL = len([1 for annot in annotations.values() for _ in annot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = iter(annotations.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_to_color(n):\n",
    "    nb2 = [int(b) for b in list(format(n,'06b'))]\n",
    "    return list(reversed([nb2[i] * 64 + nb2[i+3] * 128 for i in range(3)])) #BGR -> RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_color(color):\n",
    "    im.show(np.array(idx_to_color(color))[np.newaxis, np.newaxis, ...])\n",
    "    \n",
    "def notify_error(msg):\n",
    "    sgm_cv2 = transforms.ToTensor()(Image.open(sgm_path + name + '.png').convert(\"RGB\"))\n",
    "    sgm_cv2 = im.pil_to_cv2(sgm_cv2.numpy())\n",
    "    if first:\n",
    "        \n",
    "        print(f'Number of bboxes for this image = {len(annots)}')\n",
    "        for k, annot2 in enumerate(annots):\n",
    "            _, _, bbox2 = annot2\n",
    "            im.show(im.draw_cbbox(img_cv2, bbox2, color = idx_to_color(k+1)))\n",
    "            im.show(im.draw_cbbox(sgm_cv2, bbox2, color = idx_to_color(k+1)))\n",
    "    print('==============\\n')\n",
    "        \n",
    "    print(msg + f' for img {i} {name} and bbox {j}')\n",
    "    im.show(sgm_cv2[ymin:ymax, xmin:xmax, :])\n",
    "    print(f'Bbox associated color : expected color')\n",
    "    show_color(expected_color)\n",
    "    print('_____________________________________\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1_match = 0\n",
    "top2_match = 0\n",
    "match      = 0\n",
    "skipped    = 0\n",
    "wrong      = 0\n",
    "\n",
    "for i in range(N):\n",
    "    first = True\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    skip = 0\n",
    "    \n",
    "    img, sgm = next(data)\n",
    "    img = torch.squeeze(img)\n",
    "    sgm = torch.squeeze(sgm)\n",
    "    img_pil = img\n",
    "    img_cv2 = im.pil_to_cv2(img.numpy())\n",
    "    sgm     = im.f1_to_f255(sgm.numpy())\n",
    "    \n",
    "    name, annots = next(annotations)\n",
    "    \n",
    "    for j, annot in enumerate(annots):\n",
    "        _, _, bbox = annot\n",
    "        \n",
    "        expected_color = j + 1 - skip\n",
    "        \n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        crop_sgm = sgm[ymin:ymax, xmin:xmax]\n",
    "        crop_sgm = crop_sgm[crop_sgm != 0]\n",
    "        crop_sgm = crop_sgm[crop_sgm != 255]\n",
    "        if len(np.unique(crop_sgm)) > 0: # more than background and undef\n",
    "            \n",
    "            unique, counts = np.unique(crop_sgm, return_counts = True)\n",
    "            counts = np.argsort(-counts)\n",
    "\n",
    "            if expected_color == unique[counts][0].tolist():\n",
    "                top1_match += 1\n",
    "            elif expected_color == unique[counts][1].tolist():\n",
    "                top2_match += 1\n",
    "            elif expected_color in unique[counts].tolist():\n",
    "                match      += 1\n",
    "            else:\n",
    "                notify_error('Colors dont match')\n",
    "                first = False\n",
    "                \n",
    "                print(\"Wrong\")\n",
    "                wrong += 1\n",
    "        else:\n",
    "            val = annotations_clean[name]\n",
    "            val.pop(j - skip)\n",
    "            annotations_clean[name] = val\n",
    "            skip += 1\n",
    "            \n",
    "            notify_error('No true color')\n",
    "            first = False\n",
    "            \n",
    "            print(\"Skipped\")\n",
    "            skipped += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'# top1_match \\t = {top1_match}')\n",
    "print(f'# top2_match \\t = {top2_match}')\n",
    "print(f'# match \\t = {match}')\n",
    "print(f'# skipped \\t = {skipped}')\n",
    "print(f'# wrong\\t\\t = {wrong}')\n",
    "print(f'__________________ +')\n",
    "print(f'Total \\t\\t = {top1_match + top2_match + match + skipped + wrong} / {N_TOTAL}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOTAL_CLEAN = len([1 for annot in annotations_clean.values() for _ in annot])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{N_TOTAL - skipped} == {N_TOTAL_CLEAN}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.save_json(json_path + 'voc-object-annotations-clean', annotations_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(torch.utils.data.DataLoader(data_tbl,\n",
    "                                        batch_size = 1,\n",
    "                                        shuffle = False,\n",
    "                                        num_workers = 2))\n",
    "annotations_clean_iter = iter(annotations_clean.items())\n",
    "\n",
    "top1_match = 0\n",
    "top2_match = 0\n",
    "match      = 0\n",
    "skipped    = 0\n",
    "wrong      = 0\n",
    "\n",
    "for i in range(N):\n",
    "    first = True\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    skip = 0\n",
    "    \n",
    "    img, sgm = next(data)\n",
    "    img = torch.squeeze(img)\n",
    "    sgm = torch.squeeze(sgm)\n",
    "    img_pil = img\n",
    "    img_cv2 = im.pil_to_cv2(img.numpy())\n",
    "    sgm     = im.f1_to_f255(sgm.numpy())\n",
    "    \n",
    "    name, annots = next(annotations_clean_iter)\n",
    "    \n",
    "    for j, annot in enumerate(annots):\n",
    "        _, _, bbox = annot\n",
    "        \n",
    "        expected_color = j + 1 - skip\n",
    "        \n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        crop_sgm = sgm[ymin:ymax, xmin:xmax]\n",
    "        crop_sgm = crop_sgm[crop_sgm != 0]\n",
    "        crop_sgm = crop_sgm[crop_sgm != 255]\n",
    "        if len(np.unique(crop_sgm)) > 0: # more than background and undef\n",
    "            \n",
    "            unique, counts = np.unique(crop_sgm, return_counts = True)\n",
    "            counts = np.argsort(-counts)\n",
    "\n",
    "            if expected_color == unique[counts][0].tolist():\n",
    "                top1_match += 1\n",
    "            elif expected_color == unique[counts][1].tolist():\n",
    "                top2_match += 1\n",
    "            elif expected_color in unique[counts].tolist():\n",
    "                match      += 1\n",
    "            else:\n",
    "                wrong += 1\n",
    "        else:\n",
    "            skipped += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'# top1_match \\t = {top1_match}')\n",
    "print(f'# top2_match \\t = {top2_match}')\n",
    "print(f'# match \\t = {match}')\n",
    "print(f'# skipped \\t = {skipped}')\n",
    "print(f'# wrong\\t\\t = {wrong}')\n",
    "print(f'__________________ +')\n",
    "print(f'Total \\t\\t = {top1_match + top2_match + match + skipped + wrong} / {N_TOTAL_CLEAN}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
