{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import timeit\n",
    "import gc\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import utils.image as im\n",
    "import utils.cam as cam\n",
    "import utils.metrics as m\n",
    "import utils.json as json\n",
    "import utils.path as path\n",
    "import utils.segmentation as sg\n",
    "from utils.VOCSegmentation import VOCSegmentation\n",
    "\n",
    "\n",
    "# PATHS\n",
    "\n",
    "root_path   = path.goback_from_current_dir(0)\n",
    "json_path   = root_path + 'json\\\\'\n",
    "output_path = root_path + 'output\\\\'\n",
    "\n",
    "Path(output_path).mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camnet = cam.Cam()\n",
    "\n",
    "data = VOCSegmentation(root = root_path,\n",
    "                           year = '2012',\n",
    "                           image_set = 'trainval',\n",
    "                           download = False,\n",
    "                           transform = transforms.ToTensor(),\n",
    "                           target_transform = transforms.ToTensor(),\n",
    "                           transforms = None,\n",
    "                           target = 'Object')\n",
    "data = iter(torch.utils.data.DataLoader(data,\n",
    "                                        batch_size = 1,\n",
    "                                        shuffle = False,\n",
    "                                        num_workers = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = json.open_json(json_path + \"voc-object-annotations-clean\")\n",
    "N = len(annotations)\n",
    "annotations = iter(annotations.items())\n",
    "\n",
    "classes    = json.open_json(json_path + \"voc-classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N):\n",
    "    gc.collect()\n",
    "    \n",
    "    img, sgm = next(data)\n",
    "    sgm = torch.squeeze(sgm)\n",
    "\n",
    "    sgm      = im.f1_to_f255(sgm.numpy())\n",
    "    undef    = np.where(sgm == 255, 1, 0).astype(bool)\n",
    "    \n",
    "    name, annots = next(annotations)\n",
    "\n",
    "    for annot in annots:\n",
    "        c, _, _ = annot\n",
    "        k = classes.index(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
