{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import timeit\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import utils.image as im\n",
    "import utils.cam as cam\n",
    "import utils.grabcut as gc\n",
    "import utils.voc as voc\n",
    "import utils.json as json\n",
    "from utils.VOCSegmentation import VOCSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r'C:\\Users\\Nicol\\Documents\\EPFL\\BA7\\Project\\Code\\voc\\\\'\n",
    "\n",
    "json_path = r'C:\\Users\\Nicol\\Documents\\EPFL\\BA7\\Project\\Code\\voc\\json\\\\'\n",
    "\n",
    "output_path = r'C:\\Users\\Nicol\\Documents\\EPFL\\BA7\\Project\\Code\\voc\\sessions\\session3\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "camnet = cam.Cam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tbl = VOCSegmentation(root = root_path,\n",
    "                           year = '2012',\n",
    "                           image_set = 'trainval',\n",
    "                           download = False,\n",
    "                           transform = transforms.ToTensor(),\n",
    "                           target_transform = transforms.ToTensor(),\n",
    "                           transforms = None,\n",
    "                           target = 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = iter(torch.utils.data.DataLoader(data_tbl,\n",
    "                                        batch_size = 1,\n",
    "                                        shuffle = False,\n",
    "                                        num_workers = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = json.open_json(json_path + \"voc-class-annotations\")\n",
    "N = len(annotations)\n",
    "annotations = iter(annotations.items())\n",
    "\n",
    "classes = json.open_json(json_path + \"voc-classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicol\\Miniconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image nb 0\n",
      "Time spent               =   0 m  1 s\n",
      "Estimated time remaining =  88 m 48 s\n",
      "Mean IoU                 = 0.029\n",
      "\n",
      "Image nb 1\n",
      "Time spent               =   0 m  2 s\n",
      "Estimated time remaining =  64 m 37 s\n",
      "Mean IoU                 = 0.168\n",
      "\n",
      "Image nb 2\n",
      "Time spent               =   0 m  3 s\n",
      "Estimated time remaining =  64 m 26 s\n",
      "Mean IoU                 = 0.176\n",
      "\n",
      "Image nb 3\n",
      "Time spent               =   0 m  5 s\n",
      "Estimated time remaining =  60 m 59 s\n",
      "Mean IoU                 = 0.297\n",
      "\n",
      "Image nb 4\n",
      "Time spent               =   0 m  5 s\n",
      "Estimated time remaining =  55 m  8 s\n",
      "Mean IoU                 = 0.265\n",
      "\n",
      "Image nb 5\n",
      "Time spent               =   0 m  7 s\n",
      "Estimated time remaining =  62 m 51 s\n",
      "Mean IoU                 = 0.288\n",
      "\n",
      "Image nb 6\n",
      "Time spent               =   0 m  8 s\n",
      "Estimated time remaining =  62 m  2 s\n",
      "Mean IoU                 = 0.283\n",
      "\n",
      "Image nb 7\n",
      "Time spent               =   0 m  9 s\n",
      "Estimated time remaining =  60 m 17 s\n",
      "Mean IoU                 = 0.301\n",
      "\n",
      "Image nb 8\n",
      "Time spent               =   0 m 11 s\n",
      "Estimated time remaining =  60 m 34 s\n",
      "Mean IoU                 = 0.316\n",
      "\n",
      "Image nb 9\n",
      "Time spent               =   0 m 14 s\n",
      "Estimated time remaining =  70 m 41 s\n",
      "Mean IoU                 = 0.332\n",
      "\n",
      "Image nb 10\n",
      "Time spent               =   0 m 17 s\n",
      "Estimated time remaining =  78 m 10 s\n",
      "Mean IoU                 = 0.323\n",
      "\n",
      "Image nb 11\n",
      "Time spent               =   0 m 18 s\n",
      "Estimated time remaining =  74 m 27 s\n",
      "Mean IoU                 = 0.349\n",
      "\n",
      "Image nb 12\n",
      "Time spent               =   0 m 19 s\n",
      "Estimated time remaining =  73 m 28 s\n",
      "Mean IoU                 = 0.351\n",
      "\n",
      "Image nb 13\n",
      "Time spent               =   0 m 21 s\n",
      "Estimated time remaining =  74 m 45 s\n",
      "Mean IoU                 = 0.335\n",
      "\n",
      "Image nb 14\n",
      "Time spent               =   0 m 26 s\n",
      "Estimated time remaining =  86 m 23 s\n",
      "Mean IoU                 = 0.318\n",
      "\n",
      "Image nb 15\n",
      "Time spent               =   0 m 31 s\n",
      "Estimated time remaining =  95 m 55 s\n",
      "Mean IoU                 = 0.305\n",
      "\n",
      "Image nb 16\n",
      "Time spent               =   0 m 32 s\n",
      "Estimated time remaining =  91 m 49 s\n",
      "Mean IoU                 = 0.311\n",
      "\n",
      "Image nb 17\n",
      "Time spent               =   0 m 33 s\n",
      "Estimated time remaining =  90 m  7 s\n",
      "Mean IoU                 = 0.327\n",
      "\n",
      "Image nb 18\n",
      "Time spent               =   0 m 35 s\n",
      "Estimated time remaining =  89 m 12 s\n",
      "Mean IoU                 = 0.320\n",
      "\n",
      "Image nb 19\n",
      "Time spent               =   0 m 36 s\n",
      "Estimated time remaining =  87 m 40 s\n",
      "Mean IoU                 = 0.318\n",
      "\n",
      "Image nb 20\n",
      "Time spent               =   0 m 37 s\n",
      "Estimated time remaining =  86 m 55 s\n",
      "Mean IoU                 = 0.310\n",
      "\n",
      "Image nb 21\n",
      "Time spent               =   0 m 39 s\n",
      "Estimated time remaining =  85 m 38 s\n",
      "Mean IoU                 = 0.320\n",
      "\n",
      "Image nb 22\n",
      "Time spent               =   0 m 41 s\n",
      "Estimated time remaining =  86 m  3 s\n",
      "Mean IoU                 = 0.316\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a3a5e2e02ed4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mimg_cam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcam_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_pil\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_cam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mgcmask_cam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcam_to_gcmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_cam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrabcut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_cv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgcmask_cam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'MASK'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mtrue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msgm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdilation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\EPFL\\BA7\\Project\\Code\\voc\\utils\\grabcut.py\u001b[0m in \u001b[0;36mgrabcut\u001b[1;34m(img, mask, iterCount, mode)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m65\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"float\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0miterCount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miterCount\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         mode = cv2.GC_INIT_WITH_MASK)\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mquaternary_mask3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m                                 \u001b[1;31m# [0, 1, 2, 3]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "IoU = np.array([])\n",
    "time = np.array([])\n",
    "\n",
    "for i in range(N):\n",
    "    start = timeit.default_timer()\n",
    "    \n",
    "    img, sgm = next(data)\n",
    "    img, sgm = torch.squeeze(img), torch.squeeze(sgm)\n",
    "\n",
    "    img_pil = img\n",
    "    img_cv2 = im.pil_to_cv2(img.numpy())\n",
    "    sgm     = im.f1_to_f255(sgm.numpy())\n",
    "    \n",
    "    name, annots = next(annotations)\n",
    "    \n",
    "    for c in annots:\n",
    "        \n",
    "        img_cam = camnet.get_top(img_pil, c)\n",
    "        img_cam = cam.cam_process(img_pil, img_cam)\n",
    "        gcmask_cam = cam.cam_to_gcmask(img_cam, a = 0.0, b = 0.2, c = 1.0)\n",
    "        _, _, pred = gc.grabcut(img_cv2, gcmask_cam, mode = 'MASK')\n",
    "        \n",
    "        true = voc.true_mask(sgm, classes.index(c) + 1, dilation = 0)\n",
    "        \n",
    "        IoU = np.append(IoU, voc.IoU_acc_undef(true, pred, sgm))\n",
    "        \n",
    "    stop = timeit.default_timer()\n",
    "    time = np.append(time, stop - start)\n",
    "    if i % 1 == 0:\n",
    "        print(f'Image nb {i}')\n",
    "        print(f'Time spent               = ' + voc.time_str(np.sum(time)))\n",
    "        print(f'Estimated time remaining = ' + voc.time_str(np.mean(time) * (N - 1 - i)))\n",
    "        print(f'Mean IoU                 =  {np.mean(IoU) :.3f}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Mean IoU = {np.mean(IoU)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Nicol\\Documents\\EPFL\\BA7\\Project\\Code\\voc\\json\\voc-object-annotations-clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mIoU'] = IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(output_dir + 'IoU.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
